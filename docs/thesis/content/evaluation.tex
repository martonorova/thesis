\chapter{Evaluation}

In this chapter, I present an evaluation of the implemented components, introducing their advantages and disadvantages.

%---
\section{Proxy (Gateway)}
%---

%---
\subsection{Advantages}
%---

The Gateway component I created successfully suits the declared requirements discussed in section \ref{goals} and \ref{proxy-design}.

It implements the necessary interfaces in order to be able to communicate with Grafana (specifically, with the SimpleJSON data source plugin). It can also send requests to its backend storage, which is a RapidMiner Server exposing multiple web services.

It conforms to the expectations of having the capabilities to transform between the data format that the RapidMiner Server uses to provide its results and the format that the SimpleJSON data source plugin requires so it can parse the requested data in order for it to be visualized in Grafana.

Furthermore, the Gateway component introduced a new feature to the built-in SimpleJSON. It enabled the querying of  the available parameters for each web service, which made it possible to dynamically list them for the user, who know does not to be familiar with the details of customizing the queries. This ability enforces the many interactivity features of Grafana.

Regarding the effectiveness of this component, there is also an operations related convenience that needs to be mentioned among its advantages. The created Gateway runs in a Docker container, which enables the simple portability of this tool, enhancing it usability in various types of environments.

%---
\subsection{Disadvantages} \label{proxy-cons}
%---
% production ready webserver
% use of decarative data tranformation in case of more complex data structure in the future
% in case of static processes, which result do not change over time, or just daily, cache the results, this needs improvement, more meta information from the RM side too ->>> querying the possible parameter values

% to fill out the city variable, one has to know, which cities are in the dataset, --> enable querying meta information about the data set, e.g. the name of the columns

% security credentials are hard-coded, improvements on this side, at least read them from an environment variable that is included in the container on startup

Despite that the Proxy component conforms to all of the expressed requirements, there are also some disadvantages that present room for further improvements.

First of all, the way it is currently realized is that it runs on a \texttt{flask} development server that enables quick progress during the implementation phase, however, it does not provide favorable performance in a production grade environment.

Concerning the data format transformation, it was discussed in section \ref{proxy-impl} why I did not choose an existing tool that enables defining JSON transformations in a declarative way. Yet, in order to prepare for more complex data structures in the future, it would be profitable to integrate such a tool instead of further extending my own algorithm.

Another downside of the current implementation is that it does not provide any information about the possible values of the available parameters. For example in the case of the Dashboard that was mentioned in section \ref{final-dashboard}, the user does not know which cities can write into the text box of the variable without further knowledge about the data set. Of course, in order for this functionality to work, the backend storage would have to support it too, but nonetheless, the Gateway component could have this feature.

There is also a performance issue regarding the Gateway component which does not reside on code level, but rather in the design. There are use-cases, when the exposed processes are not time-dependent or change their results over longer periods of time, for example every day or week. Querying these processes too frequently can cause a significant unnecessary overhead for the system. Some kind of caching method would probably solve this problem, for example if the Proxy component tracked the incoming requests by the name of the web service and the attached parameters. Additionally, the backend storage would have to expose some meta information about processes of such kind, providing the usual time interval for each process after which the results are probably different as those of the previous queries.

I have to mention some security concerns too about the current realization of the Gateway component. In order to be able to query the results of the web services, one must posses the correct credentials to invoke these endpoints on the RapidMiner Server. At the moment, these credentials are hard-coded into the Proxy component, which presents a serious security vulnerability. A possible solution for this problem would be reading these sensitive information from environment variables, which are set on container startup.

